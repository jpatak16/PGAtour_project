---
title: "PGA Tour Project"
author: "Jeremy Patak"
date: '2022-06-08'
output: 
  html_document:
    theme: united
    toc: yes
    toc_float: yes
---
```{r setup, echo=FALSE}
pacman::p_load(tidyverse, knitr, kableExtra, lubridate, binsreg, rsample, recipes, parsnip, workflows, tune, glmnet, ranger, parallel, vip, rvest, odds.converter)

options(width = 100)
knitr::opts_chunk$set(echo = FALSE) ## dont show code
knitr::opts_chunk$set(warning = FALSE) ## Limit warnings
knitr::opts_chunk$set(message = FALSE) ## Limit warnings
knitr::opts_chunk$set(cache = TRUE)

data = read.csv('all_tourn.csv')
```

# Introduction

The Masters Tournament is one of four majors on the PGA Tour each year, and widely considered the biggest and best golf tournament in the world. I wanted to see if I could predict the results of that tournament using data science. The most common gambling bets you can make in golf are tournament winner, top-10 finisher, and making/missing the cut, so I decided these would be the things I try to predict. One of my questions will be if any of these three outcomes are easier or harder to predict than the others. I also am interested in what features are best at predicting these outcomes. 

I am going to attempt to answer these questions by predicting a mean and variance for each golfer participating in the Masters Tournament, then use those values to run many simulations and see how often each golfer wins, places top 10, and makes the cut.

# Data

To get my data, I webscraped the PGA Tour leaderboards from [ESPN's website](https://www.espn.com/golf/leaderboard). Each tournament was a different webpage, and I aggregated those pages into one csv that I loaded into this notebook. I collected all the individual tournaments from each of the past 16 seasons (starting in the 2007 season until present day). The table below is a random sample preview of how the collected data looks. You can look at my [GitHub repo](https://github.com/jpatak16/PGAtour_project) for this project to see more details about how the data was scraped. 

```{r table preview}
#preview table
set.seed(12)
data[sample(1:nrow(data)), ] %>% head(n=3) %>%
  kable('html', row.names = FALSE) %>% kable_styling('striped') %>% scroll_box(width = '100%')
```

Since I am trying to make predictions for the yearly Masters Tournament, I need to manipulate this data set into one that I can use to run predictive models on. I need one row for each participant for each year's Masters Tournament, then I will need to create a set of predictors using the data I scraped from ESPN.

The first thing to think about when designing our data set is that we want to predict how golfers do compared to each other, rather than compared to par or total score. This is because due to course difficulty, weather conditions, or any other sort of external variation, a score that is good enough to place top-5 at one tournament may not be good enough to make the cut at the next. Because of this, we want our score variables to be in reference to the field of other golfers.

When calculating these scores, we can compare the player's round score to the mean round score or the median round score. 

```{r mean vs median}
#create table with means and medians of every round of every tournament in our data
round_summ = data %>% group_by(TID) %>%
  summarise(R1mean = mean(R1, na.rm=TRUE), R1med = median(R1, na.rm = TRUE),
            R2mean = mean(R2, na.rm=TRUE), R2med = median(R2, na.rm = TRUE),
            R3mean = mean(R3, na.rm=TRUE), R3med = median(R3, na.rm = TRUE),
            R4mean = mean(R4, na.rm=TRUE), R4med = median(R4, na.rm = TRUE))

#plot relationship between a rounds mean and median
ggplot(round_summ, aes(R1mean, R1med)) +
  geom_point() + geom_abline(slope=1, intercept = 0) + geom_smooth(method = 'lm') +
  xlab('Round 1 Means') + ylab('Round 1 Medians') +
  scale_x_continuous(limits = c(67,77), breaks = seq(67,77,2)) + 
  scale_y_continuous(limits = c(67,77), breaks = seq(67,77,2)) +
  ggtitle('Round Means vs Medians', 
          subtitle = 'The blue line is a line of best fit. The black line represents where mean=median.')
```

As you can see in the plot above, they are very closely related to each other, but means tend to be higher estimates than medians. Only Round 1 means/medians are plotted above, but all rounds displayed this same pattern. This suggest that the distribution of scores is slightly skewed towards higher scores. You will see that this is true soon, but for the purposes of generating golfer round scores relative to other golfers, I will use the median since it better accounts for outliers. 

```{r adjust score reference points}
#change scores in data set to be relative to the rest of the golfers competing in the same round
data2 = left_join(data, round_summ, by='TID') %>% mutate(R1 = R1 - R1med,
                                                          R2 = R2 - R2med,
                                                          R3 = R3 - R3med,
                                                          R4 = R4 - R4med) %>%
  select(-c(R1mean, R1med, R2mean, R2med, R3mean, R3med, R4mean, R4med))


```

The next thing we want to consider is whether or not we think that score distributions are statistically similar for each round. I have a good feeling that they are not, because after Round 2 of most tournaments, roughly half of the field is "cut" and do not play the next two rounds. Since the golfer in the middle of the distribution of Rounds 1 & 2 should now theoretically be at the bottom of the distribution in Rounds 3 & 4, it seems like we would want to estimate different scores for them depending what round they are in. 

```{r plot round distributions}
R12 = append(round_summ$R1med, round_summ$R2med)
R34 = append(round_summ$R3med, round_summ$R4med)

rd = data.frame(x = 1, R12 = R12, R34 = R34) %>% 
  pivot_longer(-x, names_to = 'Rounds', values_to = 'Scores') %>%
  select(-x)

ggplot(rd, aes(x=Scores, fill=Rounds, color = Rounds)) +
  geom_density(alpha = .4, bw=1) +
  geom_vline(xintercept = mean(R12), color = 'pink') + 
  geom_vline(xintercept = mean(R34, na.rm = TRUE), color = 'lightblue') +
  scale_fill_discrete(labels = c('1 & 2', '3 & 4')) + 
  scale_color_discrete(labels = c('1 & 2', '3 & 4')) + 
  xlim(c(65,78))
```

We can visually see that scores in Rounds 3 and 4 appear to be lower than in Rounds 1 and 2. (We also see that the distributions are slightly left skewed, as mentioned earlier). We will run a Kolmogorov-Smirnov Test on the distributions to see if they are statistically different from each other. 

```{r ks test}
ks.test(R12, R34, alternative = 't')

rm(R12, R34, rd)
```

Our p-value is easily significant at the .01 level, so from this test we know that scores in Rounds 3 and 4 are not drawn from the same distribution as scores from Rounds 1 and 2. This confirms that we should make different mean estimates for golfers in the later two rounds than in the first two rounds.

```{r create data set}
#create a df with one row for each player at each masters tournament
MT = data2 %>% filter(grepl('Masters', tournament)) %>% 
  filter(start_date != '2007-04-05') %>%
  filter(start_date != '2020-11-12') %>%
  select(c(2, 15, 21, 7:10))

#create our outcome variables
#we will average R1 and R2 for one y var and average R3 and R4 for the other y var
MT$R12 = ifelse(is.na(MT$R2), MT$R1, (MT$R1 + MT$R2)/2)
MT$R34 = ifelse(is.na(MT$R4), MT$R3, (MT$R3 + MT$R4)/2)

#remove round scores
MT = MT %>% select(1, 2, 3, 8, 9)
```

We set up our data frame by having one row for each golfer in each Masters Tournament. We will have two outcome variables in each row, one for the mean of the first two rounds one one for the mean of the second two rounds. Remember, all of our scores now are relative to the median golfer in that round, and not the total strokes or relative to par. 

I excluded the first year's (2007) Masters Tournament from our data set because I want to use the year leading up to each Masters as predictors, and my data doesn't include 2006 data, so we'd have no predictors for it. I also excluded the 2020 Masters since that season was heavily affected by COVID and caused cancellation of many tournaments leading up to the Masters, as well as the Masters being delayed 7 months. 

Now we need to create features that can help predict our outcome variables. 

```{r create a predictor}
#create an empty column to fill with data
MT$cuts_percent_last_year = NA
for(i in 1:nrow(MT)){
  #grab player and start date from each observation
  name = MT$player[i]
  date = MT$start_date[i]
  one_yr_prior = ymd(date) - years(1)
  #get a list of tournaments the player has played in within a year of masters start date
  tourns = data2 %>% filter(player == name) %>% filter(start_date < date) %>% filter(start_date > one_yr_prior)
  #find number of tournaments played in
  played_in = nrow(tourns)
  #find number of cuts made
  cuts_made = tourns %>% filter(!is.na(R1)) %>% filter(cut == 'FALSE') %>% 
    filter(withdraw == 'FALSE') %>% filter(dq == 'FALSE')
  more = tourns %>% filter(dq == 'TRUE') %>% filter(!is.na(R3))
  cuts_made = rbind(cuts_made, more) %>% nrow()
  #add cuts made percentage to df
  MT$cuts_percent_last_year[i] = cuts_made / played_in
}

rm(more, tourns, cuts_made, date, i, name, one_yr_prior, played_in)
```

I first wanted to see if making cuts in tournaments in the year leading up to the Masters is related to Masters score. I create two binned scatter plots; the x-axis is a created feature representing the percentage of time a golfer makes the cut in tournaments he played in during the year prior to the Masters. The y-axis is score in the first two or last two rounds of the Masters. 

```{r plot cuts vs master score, out.width='50%'}
par(mar = c(4, 4, .1, .1))

a = binsreg(MT$R12, MT$cuts_percent_last_year)
b = binsreg(MT$R34, MT$cuts_percent_last_year)

rm(a,b)
```

As you can see, there is a clear trend showing that as a golfer makes more cuts, their score in the Masters decreases. I will use this feature when making predictions, and break it down into more specific time periods: the month prior, 1 months to 6 months prior, and 6 months to 1 year prior. 

Along with cuts made, I want to use top-10 finishes and tournament wins in the prior year as predictors for Masters round score.

```{r create many predictors}
#create column for desired features
MT$cuts_percent_last_month = NA
MT$cuts_percent_1m_to_6m = NA
MT$cuts_percent_6m_to_1yr = NA
MT$top10_last_year = NA
MT$top10_last_month = NA
MT$top10_1m_to_6m = NA
MT$top10_6m_to_1yr = NA
MT$wins_last_year = NA
MT$wins_last_month = NA
MT$wins_1m_to_6m = NA
MT$wins_6m_to_1yr = NA

#fill empty feature columns
for(i in 1:nrow(MT)){
  #grab player and start date from each observation
  name = MT$player[i]
  date = MT$start_date[i]
  #grab dates relative to start date of observation
  one_yr_prior = ymd(date) - years(1)
  one_month_prior = ymd(date) - months(1)
  six_month_prior = ymd(date) - months(6)
  #get a list of tournaments the player has played in within the specified time periods
  tourns_last_year = data2 %>% filter(player == name) %>% filter(start_date < date) %>% filter(start_date >= one_yr_prior)
  tourns_last_month = data2 %>% filter(player == name) %>% filter(start_date < date) %>% filter(start_date >= one_month_prior)
  tourns_1m_to_6m = data2 %>% filter(player == name) %>% filter(start_date < one_month_prior) %>% filter(start_date >= six_month_prior)
  tourns_6m_to_1yr = data2 %>% filter(player == name) %>% filter(start_date < six_month_prior) %>% filter(start_date >= one_yr_prior)
  #find number of tournaments played in for the given time period
  played_in_last_year = nrow(tourns_last_year)
  played_in_last_month = nrow(tourns_last_month)
  played_in_1m_to_6m = nrow(tourns_1m_to_6m)
  played_in_6m_to_1yr = nrow(tourns_6m_to_1yr)
  #find number of cuts made
  cuts_made_last_year = tourns_last_year %>% filter(!is.na(R1)) %>% filter(cut == 'FALSE') %>% 
    filter(withdraw == 'FALSE') %>% filter(dq == 'FALSE')
  more_last_year = tourns_last_year %>% filter(dq == 'TRUE') %>% filter(!is.na(R3))
  cuts_made_last_year = rbind(cuts_made_last_year, more_last_year) %>% nrow()
  
  cuts_made_last_month = tourns_last_month %>% filter(!is.na(R1)) %>% filter(cut == 'FALSE') %>% 
    filter(withdraw == 'FALSE') %>% filter(dq == 'FALSE')
  more_last_month = tourns_last_month %>% filter(dq == 'TRUE') %>% filter(!is.na(R3))
  cuts_made_last_month = rbind(cuts_made_last_month, more_last_month) %>% nrow()
  
  cuts_made_1m_to_6m = tourns_1m_to_6m %>% filter(!is.na(R1)) %>% filter(cut == 'FALSE') %>% 
    filter(withdraw == 'FALSE') %>% filter(dq == 'FALSE')
  more_1m_to_6m = tourns_1m_to_6m %>% filter(dq == 'TRUE') %>% filter(!is.na(R3))
  cuts_made_1m_to_6m = rbind(cuts_made_1m_to_6m, more_1m_to_6m) %>% nrow()
  
  cuts_made_6m_to_1yr = tourns_6m_to_1yr %>% filter(!is.na(R1)) %>% filter(cut == 'FALSE') %>% 
    filter(withdraw == 'FALSE') %>% filter(dq == 'FALSE')
  more_6m_to_1yr = tourns_6m_to_1yr %>% filter(dq == 'TRUE') %>% filter(!is.na(R3))
  cuts_made_6m_to_1yr = rbind(cuts_made_6m_to_1yr, more_6m_to_1yr) %>% nrow()
  #find number of top 10 finishes
  T10_last_year = tourns_last_year %>% filter(position <= 10) %>% nrow()
  T10_last_month = tourns_last_month %>% filter(position <= 10) %>% nrow()
  T10_1m_to_6m = tourns_1m_to_6m %>% filter(position <= 10) %>% nrow()
  T10_6m_to_1yr = tourns_6m_to_1yr %>% filter(position <= 10) %>% nrow()
  #find number of wins
  W_last_year = tourns_last_year %>% filter(position == 1) %>% nrow()
  W_last_month = tourns_last_month %>% filter(position == 1) %>% nrow()
  W_1m_to_6m = tourns_1m_to_6m %>% filter(position == 1) %>% nrow()
  W_6m_to_1yr = tourns_6m_to_1yr %>% filter(position == 1) %>% nrow()
  #add data to df
  MT$cuts_percent_last_year[i] = ifelse(played_in_last_year == 0, 0, cuts_made_last_year / played_in_last_year)
  MT$cuts_percent_last_month[i] = ifelse(played_in_last_month == 0, 0, cuts_made_last_month / played_in_last_month)
  MT$cuts_percent_1m_to_6m[i] = ifelse(played_in_1m_to_6m == 0, 0, cuts_made_1m_to_6m / played_in_1m_to_6m)
  MT$cuts_percent_6m_to_1yr[i] = ifelse(played_in_6m_to_1yr == 0, 0, cuts_made_6m_to_1yr / played_in_6m_to_1yr)
  MT$top10_last_year[i] = T10_last_year
  MT$top10_last_month[i] = T10_last_month
  MT$top10_1m_to_6m[i] = T10_1m_to_6m
  MT$top10_6m_to_1yr[i] = T10_6m_to_1yr
  MT$wins_last_year[i] = W_last_year
  MT$wins_last_month[i] = W_last_month
  MT$wins_1m_to_6m[i] = W_1m_to_6m
  MT$wins_6m_to_1yr[i] = W_6m_to_1yr
}

rm(more_1m_to_6m, more_6m_to_1yr, more_last_month, more_last_year, tourns_1m_to_6m, tourns_6m_to_1yr, tourns_last_month, tourns_last_year, cuts_made_1m_to_6m, cuts_made_6m_to_1yr, cuts_made_last_month, cuts_made_last_year, date, i, name, one_month_prior, one_yr_prior, played_in_1m_to_6m, played_in_6m_to_1yr, played_in_last_month, played_in_last_year, six_month_prior, T10_1m_to_6m, T10_6m_to_1yr, T10_last_month, T10_last_year, W_1m_to_6m, W_6m_to_1yr, W_last_month, W_last_year)
```

```{r more plots, out.width='50%'}
par(mar = c(4, 4, .1, .1))

a = binsreg(MT$R12, MT$top10_last_year)
b = binsreg(MT$R34, MT$top10_last_year)
c = binsreg(MT$R12, MT$wins_last_year)
d = binsreg(MT$R34, MT$wins_last_year)

rm(a,b,c,d)
```

Here are the binned scatter plots for wins and top-10 finishes. Some are more closely related than others, but in all 4 you can see that as wins or top-10 finishes change, so does average round score. In the wins plots, you can see that having no wins doesn't predict that you will do worse than the median golfer that day (about 0 predicted score for no wins), but as you get more wins throughout the year, your predicted Masters score drops lower and lower. 

The last predictor I want to add is how the golfer did in the Masters the previous year.
```{r add column for last years masters finish}
MT = MT %>% mutate(year = year(start_date))

MT2 = data2 %>% filter(grepl('Masters', tournament)) %>% 
  select(c(2, 15, 21, 7:10, 1)) %>%
  mutate(year = year(start_date))

MT$last_year_masters_finish = NA
for(i in 1:nrow(MT)){
  last_year = MT$year[i] - 1
  name = MT$player[i]
  lym = MT2 %>% filter(year==last_year) %>% filter(player==name)
  MT$last_year_masters_finish[i] = ifelse(nrow(lym)==0, NA, lym$position[1])
}

MT = MT %>% select(1,2,18,3:5,19,6:17)

rm(MT2, lym, i, last_year, name)
```

Here is a preview of our data set with the predictors we created. We can now move on to using it to create models.

```{r preview final dataset}
set.seed(3)
MT[sample(1:nrow(MT)), ] %>% head(n=3) %>%
  kable('html', row.names = FALSE) %>% kable_styling('striped') %>% scroll_box(width = '100%')
```

# Modeling

To start my modeling process, I will separate my data into testing and training sets. My test set will be observations from the most recent Masters Tournament (2022) and my train set will be all other seasons. I will break down my train set into 6 fold cross validation, stratified by year of the tournament.

```{r test train and CV sets}
train_MT = MT %>% filter(year!=2022)
test_MT = MT %>% filter(year==2022)

cv_MT12 = train_MT %>% filter(!is.na(R12)) %>% vfold_cv(v=5, strata = year) #assign observations to cv folds
cv_MT34 = train_MT %>% filter(!is.na(R34)) %>% vfold_cv(v=5, strata = year) #assign observations to cv folds
```

I want to find a model and predictors that give a low RSME after being cross-validated because that suggest that the model is not overfit and would make good predictions on data it hasn't seen before. I want to try a few different models: a simple linear regression, an elasticnet regression model, and a non-parametric model, Random Forest. I want to try these models on a couple different sets of predictors: one set will have the predictors I created that account for the past year, and the other set will be the same predictors, but instead of one variable accounting for the last year, the year will be broken down into 3 variables that combine to make up the last year. 

### Simple Linear Regression

```{r slr last_year predictors, include=FALSE}
rec12_yr = recipe(R12 ~ last_year_masters_finish + cuts_percent_last_year + top10_last_year + wins_last_year, data = MT) %>%
  step_impute_bag(last_year_masters_finish)

slr = linear_reg() %>%
  set_engine('lm')

wf1 = workflow() %>% add_model(slr) %>% add_recipe(rec12_yr) %>% fit_resamples(cv_MT12)
wf1 %>% collect_metrics() %>% kable('html', row.names = FALSE) %>% kable_styling('striped')

rec34_yr = recipe(R34 ~ last_year_masters_finish + cuts_percent_last_year + top10_last_year + wins_last_year, data = MT) %>%
  step_impute_bag(last_year_masters_finish)

wf2 = workflow() %>% add_model(slr) %>% add_recipe(rec34_yr) %>% fit_resamples(cv_MT34)
wf2 %>% collect_metrics() %>% kable('html', row.names = FALSE) %>% kable_styling('striped')
```

Simple linear regression with our last_year predictors created a model with 2.24 RMSE for the first two rounds and an RMSE of 2.07 for the last two rounds. Lets see if that increases or decreases when we use the more specific time predictors.

```{r slr more specific predictors, include=FALSE}
rec12_m = recipe(R12 ~ . , data = MT) %>%
  update_role(player, start_date, year, TID, R34, new_role= 'ID') %>%
  step_rm(cuts_percent_last_year, top10_last_year, wins_last_year) %>%
  step_impute_bag(last_year_masters_finish)

wf3 = workflow() %>% add_model(slr) %>% add_recipe(rec12_m) %>% fit_resamples(cv_MT12)
wf3 %>% collect_metrics() %>% kable('html', row.names = FALSE) %>% kable_styling('striped')

rec34_m = recipe(R34 ~ . , data = MT) %>%
  update_role(player, start_date, year, TID, R12, new_role= 'ID') %>%
  step_rm(cuts_percent_last_year, top10_last_year, wins_last_year) %>%
  step_impute_bag(last_year_masters_finish)

wf4 = workflow() %>% add_model(slr) %>% add_recipe(rec34_m) %>% fit_resamples(cv_MT34)
wf4 %>% collect_metrics() %>% kable('html', row.names = FALSE) %>% kable_styling('striped')
```

Simple linear regression with our more specific predictors created a model with 2.23 RMSE for the first two rounds and an RMSE of 2.06 for the last two rounds. These are practically the exact same as the results with the last_year predictors.

The last thing I want to try with simple linear regression is to try and find any predictive interaction terms that I can.

```{r slr interactions, include=FALSE}
rec12_yr_i = rec12_yr %>% step_interact(~last_year_masters_finish:all_predictors())

wf5 = workflow() %>% add_model(slr) %>% add_recipe(rec12_yr_i) %>% fit_resamples(cv_MT12)
wf5 %>% collect_metrics() %>% kable('html', row.names = FALSE) %>% kable_styling('striped')

rec34_yr_i = rec34_yr %>% step_interact(~last_year_masters_finish:all_predictors())

wf6 = workflow() %>% add_model(slr) %>% add_recipe(rec34_yr_i) %>% fit_resamples(cv_MT34)
wf6 %>% collect_metrics() %>% kable('html', row.names = FALSE) %>% kable_styling('striped')
```

I interacted the golfers performance in the Masters last year with their performance variables in the tournaments in the year leading up to the Master's. It made a negligibly small difference in the resulting RMSE. (I also tried some transformations of the predictors using log, sqrt, and polynomials, but nothing made any noteworthy differences)

### Elasticnet

I now want to try a regularized linear regression model. I will cross validate the penalty and mixture values.

```{r elasticnet}
rec12_yr_en = rec12_yr %>% 
  step_normalize(all_predictors())

en = linear_reg(penalty = tune(), mixture = tune()) %>% set_engine('glmnet')

wf7 = workflow() %>% add_model(en) %>% add_recipe(rec12_yr_en) %>% 
  tune_grid(cv_MT12,
            grid = expand_grid(mixture = seq(0, 1, length.out=5), 
                               penalty = 10^seq(5, -5, length.out = 100)))

wf7 %>% collect_metrics(summarize = TRUE) %>% 
  ggplot(aes(x = penalty, y = mean, color = factor(mixture))) +
  geom_point() +
  scale_x_continuous(breaks = 10^seq(5, -5, length.out = 5), trans = 'log') +
  scale_y_continuous(limits = c(2.2,2.6)) +
  labs(title = "Elasticnet model performance",
       subtitle = 'Predicting Rounds 1 & 2 Masters Scores',
       x = "Regularization Penalty",
       y = 'RMSE',
       color = 'Elasticnet mixture')
```

After running the elasticnet model, we once again get no meaningful changes to our RMSE. Above you can see a graph of how our RMSE changes when our parameters changed in CV. As you can see, it appears that we are on an asymptote of our RMSE where we can no longer reduce the error. However, before making our predictions, I want to try a non-parametric model to see if it can do any better, so I will use a random forest.

### Random Forest

```{r random forest}
rf = rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
  set_engine('ranger', num.threads = detectCores(), importance='impurity') %>%
  set_mode('regression')

wf8 = workflow() %>% add_model(rf) %>% add_recipe(rec12_m) %>%
  tune_grid(cv_MT12,
            grid = expand_grid(mtry = c(1, 2, 3, 4, 5), 
                               trees = c(100, 200, 500),
                               min_n = c(5, 10, 20, 35, 50, 75, 100)))

wf8 %>% collect_metrics(metric = 'rmse', summarize = TRUE) %>%
  filter(.metric=='rmse') %>%
  ggplot(aes(x = min_n, y = mean, group = factor(mtry), color = factor(mtry))) +
  geom_line() +
  geom_point(size = 2.5) +
  facet_wrap(~trees, nrow = 1) +
  labs(
    title = "Random forest model performance",
    subtitle = "Predicting Rounds 1 & 2 Masters Scores",
    x = "Min data points per node",
    y = 'RMSE',
    color = 'Number of predictors') +
  scale_x_continuous(breaks = c(10, 20, 35, 50, 75, 100))
```

It also appears in the random forest model that we have reached the minimum RMSE given our predictors. Using the random forest model we ran, we can find which predictors are most important to predicting the outcome. As we can see, wins in the past year aren't very predictive of score at the Masters.

```{r variable importance}
workflow() %>% add_model(rf) %>% add_recipe(rec12_m) %>% 
  finalize_workflow(select_best(wf8, metric = "rmse")) %>% fit(data = train_MT %>% filter(!is.na(R12))) %>%
  pull_workflow_fit() %>%
  vip(aesthetics= list(fill='darkgreen'))
```

Since all of our models produced basically identical results, we will use the simplest one to make predictions with. Our simplest model is our linear model with no interactions and only using the last_year predictors.

### Make Predictions 

```{r make preds for R12}
#prep and juice data frame
lm_data_12 = recipe(R12 ~ 
                      last_year_masters_finish + cuts_percent_last_year + top10_last_year + wins_last_year, data = train_MT) %>%
  step_impute_bag(last_year_masters_finish) %>%
  prep() %>% juice()

#train lm
lm12 = lm(R12 ~ last_year_masters_finish + cuts_percent_last_year + top10_last_year + wins_last_year, lm_data_12)

#prep and juice test data frame
lm_data_12_new = recipe(R12 ~ 
                      last_year_masters_finish + cuts_percent_last_year + top10_last_year + wins_last_year, data = test_MT) %>%
  step_impute_bag(last_year_masters_finish) %>%
  prep() %>% juice()

#make df to store predictions
Masters22_preds = data.frame(player = test_MT$player)

#make predictions on test data frame
Masters22_preds$R12pred = predict(lm12, newdata=lm_data_12_new)

#find sd for each golfer
#find all R1 and R2 scores in the past 3 years and put them into 1 list
R12 = rbind(data2 %>% filter(start_date<'2022-04-07') %>% filter(start_date>'2019-04-01') %>% select(player, R1) %>% rename(R12 = R1), data2 %>% select(player, R2) %>% rename(R12=R2))
#by golfer, find how many R1 and R2 scores they have, then find the sd of those scores
sd12 = R12 %>% group_by(player) %>% filter(!is.na(R12)) %>% summarise(count = length(R12), sd12 = sd(R12, na.rm = TRUE))
#if the golfer has too few of R1 and R2 scores, assign them the mean sd for golfers with too few of scores
sd12_low_count = sd12 %>% filter(count<6)
sd12$sd12 = ifelse(sd12$count<6, mean(sd12_low_count$sd12, na.rm=TRUE), sd12$sd12)

Masters22_preds = left_join(Masters22_preds, sd12) %>% select(-count)
```

```{r make preds for R34}
#prep and juice data frame
lm_data_34 = recipe(R34 ~ 
                      last_year_masters_finish + cuts_percent_last_year + top10_last_year + wins_last_year, data = train_MT) %>%
  step_impute_bag(last_year_masters_finish) %>%
  prep() %>% juice()

#train lm
lm34 = lm(R34 ~ last_year_masters_finish + cuts_percent_last_year + top10_last_year + wins_last_year, lm_data_34)

#prep and juice test data frame
lm_data_34_new = recipe(R34 ~ 
                      last_year_masters_finish + cuts_percent_last_year + top10_last_year + wins_last_year, data = test_MT) %>%
  step_impute_bag(last_year_masters_finish) %>%
  prep() %>% juice()

#make predictions on test data frame
Masters22_preds$R34pred = predict(lm34, newdata=lm_data_34_new)

#find sd for each golfer
#find all R1 and R2 scores in the past 3 years and put them into 1 list
R34 = rbind(data2 %>% filter(start_date<'2022-04-07') %>% filter(start_date>'2019-04-01') %>% select(player, R3) %>% rename(R34 = R3), data2 %>% select(player, R4) %>% rename(R34=R4))
#by golfer, find how many R1 and R2 scores they have, then find the sd of those scores
sd34 = R34 %>% group_by(player) %>% filter(!is.na(R34)) %>% summarise(count = length(R34), sd34 = sd(R34, na.rm = TRUE))
#if the golfer has too few of R1 and R2 scores, assign them the mean sd for golfers with too few of scores
sd34_low_count = sd34 %>% filter(count<6)
sd34$sd34 = ifelse(sd34$count<6, mean(sd34_low_count$sd34, na.rm=TRUE), sd34$sd34)

Masters22_preds = left_join(Masters22_preds, sd34) %>% select(-count)
Masters22_preds$sd34 = ifelse(is.na(Masters22_preds$sd34), mean(sd34_low_count$sd34, na.rm=TRUE), Masters22_preds$sd34)
```

After predicting the means and calculating the standard deviation for each golfer participating, we end up with a data frame that looks like this that we can use to run simulations.

```{r preview predicted means and sd}
Masters22_preds[sample(1:nrow(Masters22_preds)), ] %>% head(n=3) %>%
  kable('html', row.names = FALSE) %>% kable_styling('striped')
```

```{r clear junk from environment}
rm(cv_MT, cv_MT12, cv_MT34, en, lm_data_12, lm_data_12_new, lm_data_34, lm_data_34_new, lm12, lm34, R12, R34, rec12_m, rec12_yr, rec12_yr_en, rec12_yr_i, rec34_m, rec34_yr, rec34_yr_en, rec34_yr_i, rf, sd12, sd12_low_count, sd34, sd34_low_count, slr, test_MT, train_MT, wf1, wf2, wf3, wf4, wf5, wf6, wf7, wf8)
```

# Simulation

I now am going to write a function that uses our created data frame with the round means and standard deviations for each golfer that will run n simulations.
```{r make simulation function}
simulate_masters = function(x, n){
  all_sims = data.frame(sim_num = NA, player = NA, R1 = NA, R2 = NA, score_after_R2 = NA, pos_after_R2 = NA, 
                          make_cut = NA, R3 = NA, R4 = NA, score_after_R4 = NA, pos_after_R4 = NA, top10 = NA, win = NA)
  for(i in 1:n){
    this_sim = data.frame(sim_num = i, player = x$player, R1 = NA, R2 = NA, score_after_R2 = NA, pos_after_R2 = NA, 
                          make_cut = NA, R3 = NA, R4 = NA, score_after_R4 = NA, pos_after_R4 = NA, top10 = NA, win = NA)
    for(p in 1:length(x$player)){
      this_sim[p,3] = rnorm(n=1, mean=x$R12pred[p], sd=x$sd12[p])
      this_sim[p,4] = rnorm(n=1, mean=x$R12pred[p], sd=x$sd12[p])
      this_sim[p,5] = this_sim[p,3] + this_sim[p,4]
    }
    this_sim = this_sim %>% arrange(score_after_R2)
    for(p in 1:length(x$player)){
      this_sim[p,6] = p
    }
    this_sim$make_cut = ifelse(this_sim$pos_after_R2 <=52, TRUE, FALSE)
    num_made_cut = this_sim %>% filter(make_cut==TRUE) %>% nrow()
    for(p in 1:num_made_cut){
      name = this_sim$player[p]
      x2 = x %>% filter(player == name)
      this_sim[p,8] = rnorm(n=1, mean=x2$R34pred[1], sd=x2$sd34[1])
      this_sim[p,9] = rnorm(n=1, mean=x2$R34pred[1], sd=x2$sd34[1])
      this_sim[p,10] = this_sim[p,5] + this_sim[p,8] + this_sim[p,9]
    }
    this_sim = this_sim %>% arrange(score_after_R4)
    for(p in 1:length(x$player)){
      this_sim[p,11] = p
    }
    this_sim$top10 = ifelse(this_sim$pos_after_R4<=10, TRUE, FALSE)
    this_sim$win = ifelse(this_sim$pos_after_R4==1, TRUE, FALSE)
    all_sims = rbind(all_sims, this_sim)
  }
  return(all_sims[-1,])
}
```

```{r run 10000 sims}
set.seed(4308226) # ran rnorm to pick random seed
sims = simulate_masters(Masters22_preds, 10000)
```

```{r summarize sim results}
sims_results = data.frame(player = Masters22_preds$player, sim_win_percent = NA, sim_top10_percent = NA, 
                          sim_make_cut_percent = NA, sim_miss_cut_percent = NA)
for(p in 1:length(sims_results$player)){
  name = sims_results$player[p]
  sims_p = sims %>% filter(player == name)
  win_percent = (sims_p %>% filter(win==TRUE) %>% nrow()) / nrow(sims_p)
  sims_results$sim_win_percent[p] = win_percent
  top10_percent = (sims_p %>% filter(top10==TRUE) %>% nrow()) / nrow(sims_p)
  sims_results$sim_top10_percent[p] = top10_percent
  make_cut_percent = (sims_p %>% filter(make_cut==TRUE) %>% nrow()) / nrow(sims_p)
  sims_results$sim_make_cut_percent[p] = make_cut_percent
  sims_results$sim_miss_cut_percent[p] = 1 - sims_results$sim_make_cut_percent[p]
}

rm(sims_p, make_cut_percent, name, p, top10_percent, win_percent)
```

After running 10,000 simulations of the 2022 Master's Tournament and summarizing the results, we end up with a data frame that looks like this

```{r preview simulation data}
sims_results %>% arrange(player) %>% head(n=3) %>% kable('html', row.names = FALSE) %>% kable_styling('striped')
```

# Results

After summarizing the results of our simulations, we can look and see who won, finished top 10, and made or missed the cut most often in our simulations.

```{r plot results, out.width='50%'}
ggplot(sims_results %>% arrange(-sim_win_percent) %>% head(n=10), aes(x = reorder(player, sim_win_percent), sim_win_percent)) +
  geom_bar(stat = 'identity', fill='darkgreen') + coord_flip() +
  xlab('Win Liklihood') + ylab('Golfer') +
  ggtitle('Liklihood of Winning the 2022 Masters', 
          subtitle = 'According to 10,000 simulations')

ggplot(sims_results %>% arrange(-sim_top10_percent) %>% head(n=20), aes(x = reorder(player, sim_top10_percent), sim_top10_percent)) +
  geom_bar(stat = 'identity', fill='yellow', color='darkgreen') + coord_flip() +
  xlab('Top10 Liklihood') + ylab('Golfer') +
  ggtitle('Likihood of Finishing Top 10 at the 2022 Masters', 
          subtitle = 'According to 10,000 simulations')

ggplot(sims_results %>% arrange(-sim_make_cut_percent) %>% head(n=20), aes(x = reorder(player, sim_make_cut_percent), sim_make_cut_percent)) +
  geom_bar(stat = 'identity', fill='yellow', color='darkgreen') + coord_flip() +
  xlab('Make Cut Liklihood') + ylab('Golfer') +
  ggtitle('Liklihood of Making the Cut at the 2022 Masters', 
          subtitle = 'According to 10,000 simulations')

ggplot(sims_results %>% arrange(-sim_miss_cut_percent) %>% head(n=10), aes(x = reorder(player, sim_miss_cut_percent), sim_miss_cut_percent)) +
  geom_bar(stat = 'identity', fill='darkgreen') + coord_flip() +
  xlab('Miss Cut Liklihood') + ylab('Golfer') +
  ggtitle('Liklihood of Missing the Cut at the 2022 Masters', 
          subtitle = 'According to 10,000 simulations')
```

We can then collect the betting odds from before the tournament started and find the implied percentage they give each golfer of winning, finishing top 10, and making the cut. If our simulation says they achieve those milestones more often than the betting odds imply they would, then our model says its a good bet to make.

I will collect betting odds from BetUS Sportsbook from the morning the 2022 Masters started (before any golfer teed off).

```{r collect betting odds}
odds_url = 'https://flurrysports.org/masters-2022-betting-odds-picks-to-win-make-the-cut-top-5-and-more/'

win_odds = read_html(odds_url) %>%
  html_element(xpath = '//*[@id="tps_slideContainer_60923"]/div/figure[2]/table') %>%
  html_table()

a = win_odds[-1,1:2] %>% rename(player = X1, win_odds = X2) 
b = win_odds[-1,3:4] %>% rename(player = X3, win_odds = X4)
win_odds = rbind(a,b) %>% arrange(player)
rm(a,b)

top10_odds = read_html(odds_url) %>%
  html_element(xpath = '//*[@id="tps_slideContainer_60923"]/div/figure[4]/table') %>%
  html_table()

a = top10_odds[-1,1:2] %>% rename(player = X1, top10_odds = X2) 
b = top10_odds[-1,3:4] %>% rename(player = X3, top10_odds = X4)
top10_odds = rbind(a,b) %>% arrange(player)
rm(a,b)

make_cut_odds = read_html(odds_url) %>%
  html_element(xpath = '//*[@id="tps_slideContainer_60923"]/div/figure[6]/table') %>%
  html_table()

a = make_cut_odds[-1,1:2] %>% rename(player = X1, make_cut_odds = X2) 
b = make_cut_odds[-1,3:4] %>% rename(player = X3, make_cut_odds = X4)
make_cut_odds = rbind(a,b) %>% arrange(player) %>% filter(make_cut_odds!='')
rm(a,b)

miss_cut_odds = read_html(odds_url) %>%
  html_element(xpath = '//*[@id="tps_slideContainer_60923"]/div/figure[7]/table') %>%
  html_table()

a = miss_cut_odds[-1,1:2] %>% rename(player = X1, miss_cut_odds = X2) 
b = miss_cut_odds[-1,3:4] %>% rename(player = X3, miss_cut_odds = X4)
miss_cut_odds = rbind(a,b) %>% arrange(player)
rm(a,b)

odds = left_join(win_odds, top10_odds)
odds = left_join(odds, make_cut_odds)
odds = left_join(odds, miss_cut_odds)

rm(win_odds, top10_odds, make_cut_odds, miss_cut_odds)
```

```{r convert odds to probability}
odds$bet_win_prob = odds.us2prob(as.numeric(odds$win_odds))
odds$bet_top10_prob = odds.us2prob(as.numeric(odds$top10_odds))
odds$bet_make_cut_prob = odds.us2prob(as.numeric(odds$make_cut_odds))
odds$bet_miss_cut_prob = odds.us2prob(as.numeric(odds$miss_cut_odds))
betting_probs = odds %>% select(1, 6:9)
```

```{r retrive actual results from 2022 masters}
M22_res = data2 %>% filter(start_date=='2022-04-07') %>% mutate(M22_make_cut = ifelse(fedex_points > 0, TRUE, FALSE)) %>%
  mutate(M22_win = ifelse(position == 1, TRUE, FALSE)) %>% mutate(M22_top10 = ifelse(position<=10, TRUE, FALSE)) %>%
  select(player, M22_win, M22_top10, M22_make_cut) %>% mutate(M22_miss_cut = ifelse(M22_make_cut==TRUE, FALSE, TRUE))
```

```{r combine sim betting and actual}
M22_analysis = left_join(sims_results, betting_probs)
M22_analysis = left_join(M22_analysis, M22_res)

M22_analysis$win_margin = M22_analysis$sim_win_percent - M22_analysis$bet_win_prob
M22_analysis$top10_margin = M22_analysis$sim_top10_percent - M22_analysis$bet_top10_prob
M22_analysis$make_cut_margin = M22_analysis$sim_make_cut_percent - M22_analysis$bet_make_cut_prob
M22_analysis$miss_cut_margin = M22_analysis$sim_miss_cut_percent - M22_analysis$bet_miss_cut_prob
```

After comparing the probabilities the simulation gives a golfer to win and the probabilities the betting odds give a golfer to win, we can find the widest margins to find the best and worst bets according to our model. Note that betting odds are not available for every golfer in the field. 

```{r plot sim vs betting probability}
ggplot(M22_analysis, aes(bet_win_prob, sim_win_percent, color=win_margin)) + 
  geom_point() + geom_abline(slope = 1, intercept = 0) +
  scale_color_gradient(low = '#FF0000', high = '#00FF00') +
  theme(legend.position = 'none') +
  xlab('Betting Implied Win Probability') + ylab('Simulation Implied Win Probability') +
  ggtitle('Finding Best Value Bets')


```

The black line in this graph is where the probability of winning according to the betting odds and the probability according to our simulations are the exact same. Points above the line represent good value bets according to our model, and points below the line represent bad value bets. You can see that there are more bad value bets than good value, and this holds true in top10 and making or missing the cut.

When identifying the bets we want to make, we will look for the points that are the furthest distance above the line. We will make a data frame of all the bets out model suggest we should make. We can then calculate how many of those bets we win, and what profit we would make on them.

```{r identify best bets}
best_win_bets = M22_analysis %>% filter(win_margin>0) %>% filter(sim_win_percent>=.01) %>% filter(win_margin>=.01) %>%
  select(player, bet_win_prob, M22_win)

best_top10_bets = M22_analysis %>% filter(top10_margin>0) %>% filter(sim_top10_percent>=.1) %>% filter(top10_margin>=.04) %>%
  select(player, bet_top10_prob, M22_top10)

best_make_cut_bets = M22_analysis %>% filter(make_cut_margin>0) %>% filter(sim_make_cut_percent>=.1) %>%
  filter(make_cut_margin>=.04) %>% select(player, bet_make_cut_prob, M22_make_cut)

best_miss_cut_bets = M22_analysis %>% filter(miss_cut_margin>0) %>% filter(sim_miss_cut_percent>=.1) %>%
  filter(miss_cut_margin>=.04) %>% select(player, bet_miss_cut_prob, M22_miss_cut)
```

```{r determine win and profits}
best_win_bets$result_1u_bet = ifelse(best_win_bets$M22_win==TRUE, 1/best_win_bets$bet_win_prob, -1)
best_top10_bets$result_1u_bet = ifelse(best_top10_bets$M22_top10==TRUE, 1/best_top10_bets$bet_top10_prob, -1)
best_make_cut_bets$result_1u_bet = ifelse(best_make_cut_bets$M22_make_cut==TRUE, 1/best_make_cut_bets$bet_make_cut_prob, -1)
best_miss_cut_bets$result_1u_bet = ifelse(best_miss_cut_bets$M22_miss_cut==TRUE, 1/best_miss_cut_bets$bet_miss_cut_prob, -1)
```

```{r summarize betting results}
betting_results = data.frame(prop = c('Winner', 'Top 10', 'Make Cut', 'Miss Cut', 'Total'), 
                             good_bets_identified = c(nrow(best_win_bets), nrow(best_top10_bets), 
                                                      nrow(best_make_cut_bets), nrow(best_miss_cut_bets),
                                                      NA),
                             bets_won = c(nrow(best_win_bets %>% filter(M22_win==TRUE)),
                                          nrow(best_top10_bets %>% filter(M22_top10 == TRUE)),
                                          nrow(best_make_cut_bets %>% filter(M22_make_cut == TRUE)),
                                          nrow(best_miss_cut_bets %>% filter(M22_miss_cut == TRUE)),
                                          NA),
                             net_profit = c(sum(best_win_bets$result_1u_bet), sum(best_top10_bets$result_1u_bet),
                                            sum(best_make_cut_bets$result_1u_bet), sum(best_miss_cut_bets$result_1u_bet),
                                            NA))

betting_results$good_bets_identified[5] = sum(betting_results$good_bets_identified[1:4])
betting_results$bets_won[5] = sum(betting_results$bets_won[1:4])
betting_results$net_profit[5] = sum(betting_results$net_profit[1:4])

betting_results %>% kable('html', row.names = FALSE) %>% kable_styling('striped') %>%
  row_spec(5, bold = T)
```

As you can see from the table, we found 29 bets to make and won 11 of them. If we bet 1 unit on each bet, we would profit over 17 units (with most of that profit coming from the fact that we correctly identified the winner). You can also see that we took 6 tries at identifying valued Top 10 bets, but missed on all 6. That could be a model deficiency, or just random chance. It's important to note that we only tested these model results on one year of Masters tournaments, so this could be an exceptionally good result, a exceptionally bad result, or an average result of this model. We wouldn't know until we tested more seasons. 

# Conclusions

As you could see above, for the 2022 Masters, we successfully identified some good value bets and ended up making a 17 unit profit on 29 one unit bets. This model cannot be considered successful though unless we test it on more data. 

The impact of this model would primarily be in the sports gambling market. I designed the predictors for the annual Master's tournament, but it could be generalized to other PGA tournaments as well. 

There are future improvements I plan on making. I'd like to collect more data for other predictors. The [PGA Tour Website](https://www.pgatour.com/stats.html) has stats that I'd like to webscrape. These stats account for how good a golfer is at certain areas of his game (ex. driving, putting, etc.). Since the Master's is played on the same course every year, it would make sense that if putting is very predictive of round score in 1 year, then it will also be predictive of round scores in other years. Because of this, I think those stats that break down skills will be useful predictors that could decrease my RMSE when making round score predictions. I will update this file when I implement those changes. 



